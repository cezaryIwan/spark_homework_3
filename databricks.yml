# Główny plik konfiguracyjny dla Databricks Asset Bundle
bundle:
  name: sparkhm3 # WAŻNE: Zmień na nazwę swojego projektu, np. m13_sparkstreaming

# Definicja środowisk (np. deweloperskie, produkcyjne)
targets:
  # To jest Twoje środowisko deweloperskie
  dev:
    # Ustawiamy je jako domyślne, więc komendy `deploy` i `run` będą go używać bez dodatkowych flag
    default: true
    workspace:
      # Nie musisz podawać tu hosta, Databricks CLI weźmie go z Twojej konfiguracji (którą już zrobiłeś)
      host: https://adb-1749377302190544.4.azuredatabricks.net/

# W tej sekcji definiujemy zasoby, które mają być wdrożone w Databricks (np. Joby, Pipeline'y)
resources:
  jobs:
    # Nazwa logiczna joba w tym pliku
    my_first_job:
      # Nazwa joba, która pojawi się w interfejsie Databricks
      name: "spark stream job"
      tasks:
        - task_key: main_task
          # Definicja klastra, na którym uruchomi się zadanie
          new_cluster:
            spark_version: 13.3.x-scala2.12
            node_type_id: Standard_DS3_v2
            num_workers: 1
          # Wskazanie na plik z kodem do uruchomienia
          spark_python_task:
            python_file: m13_sparkstreaming_python_azure-master/notebooks/StreamingApp.py